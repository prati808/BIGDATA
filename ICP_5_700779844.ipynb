{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nSc3IOaQNQu2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'classifier__C': 0.1, 'classifier__kernel': 'linear', 'pca__n_components': 3}\n",
      "Best cross-validation score: 0.96\n",
      "Test set score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# 3. Define parameter grid\n",
    "param_grid = {\n",
    "    'pca__n_components': [2, 3],\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# 4. GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 5. Results\n",
    "print(\"Best parameters found:\", grid.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqJp7J-jNbu6"
   },
   "source": [
    "Check for 3 fold, 5 fold and 7 fold cross validation\n",
    "\n",
    "Replace classifier, SVC with RandomForestClassifier and LogisticRegression, Perceptron, knn .\n",
    "\n",
    "Update the param_grid accordingly (e.g., for RandomForestClassifier, use n_estimators, max_depth, etc.)\n",
    "\n",
    "Also replace Gridsearch with randomnsearch function.\n",
    "\n",
    "Relplace with with your own csv dataset using code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aUipqQf8Pcao"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (150, 4)\n",
      "Target vector shape: (150,)\n",
      "First 5 rows of features:\n",
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0            5.1           3.5            1.4           0.2\n",
      "1            4.9           3.0            1.4           0.2\n",
      "2            4.7           3.2            1.3           0.2\n",
      "3            4.6           3.1            1.5           0.2\n",
      "4            5.0           3.6            1.4           0.2\n",
      "First 5 target values:\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\prati\\OneDrive\\Pictures\\datasets\\Iris.csv\")\n",
    "\n",
    "# Drop Id column since it's just an identifier\n",
    "X = data.drop(['Id', 'Species'], axis=1)\n",
    "y = data['Species']\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"First 5 rows of features:\\n{X.head()}\")\n",
    "print(f\"First 5 target values:\\n{y.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120, 4)\n",
      "X_test shape: (30, 4)\n",
      "y_train distribution:\n",
      "Species\n",
      "Iris-setosa        40\n",
      "Iris-virginica     40\n",
      "Iris-versicolor    40\n",
      "Name: count, dtype: int64\n",
      "y_test distribution:\n",
      "Species\n",
      "Iris-setosa        10\n",
      "Iris-virginica     10\n",
      "Iris-versicolor    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Check the shape of the splits\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"y_test distribution:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA()),\n",
      "                ('classifier', SVC())])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC  # placeholder classifier\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', SVC())  # Placeholder classifier; we'll change this later\n",
    "])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'classifier__max_depth': 15, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 18}\n",
      "Best cross-validation score: 0.950\n",
      "Test set score: 0.933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Replace classifier with RandomForest\n",
    "pipe.set_params(classifier=RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Define parameter distribution for RandomForest\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': randint(10, 200),\n",
    "    'classifier__max_depth': randint(2, 20),\n",
    "    'classifier__min_samples_split': randint(2, 10)\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit model on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and scores\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(f\"Best cross-validation score: {random_search.best_score_:.3f}\")\n",
    "print(f\"Test set score: {random_search.score(X_test, y_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RandomForest with CV = 3\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "=== Results with CV = 3 ===\n",
      "Best parameters: {'classifier__max_depth': 8, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 141}\n",
      "Best cross-validation score: 0.942\n",
      "Test set score: 0.967\n",
      "\n",
      "Running RandomForest with CV = 5\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "=== Results with CV = 5 ===\n",
      "Best parameters: {'classifier__max_depth': 15, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 18}\n",
      "Best cross-validation score: 0.950\n",
      "Test set score: 0.933\n",
      "\n",
      "Running RandomForest with CV = 7\n",
      "Fitting 7 folds for each of 20 candidates, totalling 140 fits\n",
      "=== Results with CV = 7 ===\n",
      "Best parameters: {'classifier__max_depth': 16, 'classifier__min_samples_split': 4, 'classifier__n_estimators': 81}\n",
      "Best cross-validation score: 0.951\n",
      "Test set score: 0.900\n"
     ]
    }
   ],
   "source": [
    "# Loop over different cross-validation values\n",
    "cv_folds = [3, 5, 7]\n",
    "\n",
    "for cv in cv_folds:\n",
    "    print(f\"\\nRunning RandomForest with CV = {cv}\")\n",
    "    \n",
    "    # Re-create pipeline with RandomForest each time to avoid parameter clashes\n",
    "    pipe.set_params(classifier=RandomForestClassifier(random_state=42))\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"=== Results with CV = {cv} ===\")\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(f\"Best cross-validation score: {random_search.best_score_:.3f}\")\n",
    "    print(f\"Test set score: {random_search.score(X_test, y_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LogisticRegression with CV = 3\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results with CV = 3 ===\n",
      "Best parameters: {'pca__n_components': None, 'classifier__penalty': 'l1', 'classifier__l1_ratio': 0.0, 'classifier__C': np.float64(1.623776739188721)}\n",
      "Best cross-validation score: 0.958\n",
      "Test set score: 0.967\n",
      "\n",
      "Running LogisticRegression with CV = 5\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results with CV = 5 ===\n",
      "Best parameters: {'pca__n_components': None, 'classifier__penalty': 'elasticnet', 'classifier__l1_ratio': 0.0, 'classifier__C': np.float64(10000.0)}\n",
      "Best cross-validation score: 0.967\n",
      "Test set score: 1.000\n",
      "\n",
      "Running LogisticRegression with CV = 7\n",
      "Fitting 7 folds for each of 20 candidates, totalling 140 fits\n",
      "=== Results with CV = 7 ===\n",
      "Best parameters: {'pca__n_components': None, 'classifier__penalty': 'elasticnet', 'classifier__l1_ratio': 0.0, 'classifier__C': np.float64(10000.0)}\n",
      "Best cross-validation score: 0.967\n",
      "Test set score: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Updated param grid to avoid invalid combos\n",
    "param_dist_logreg = {\n",
    "    'classifier__C': np.logspace(-4, 4, 20),\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'classifier__l1_ratio': [0.0, 0.5, 1.0],\n",
    "    'pca__n_components': [2, 3, None]\n",
    "}\n",
    "\n",
    "# Run RandomizedSearchCV for CV = 3, 5, 7\n",
    "for cv in [3, 5, 7]:\n",
    "    print(f\"\\nRunning LogisticRegression with CV = {cv}\")\n",
    "    \n",
    "    pipe.set_params(classifier=LogisticRegression(\n",
    "        solver='saga', max_iter=1000, random_state=42\n",
    "    ))\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist_logreg,\n",
    "        n_iter=20,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        error_score=np.nan  # skip over invalid combinations instead of throwing errors\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"=== Results with CV = {cv} ===\")\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(f\"Best cross-validation score: {random_search.best_score_:.3f}\")\n",
    "    print(f\"Test set score: {random_search.score(X_test, y_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Perceptron with CV = 3\n",
      "=== Results with CV = 3 ===\n",
      "Best parameters: {'pca__n_components': 3, 'classifier__tol': 0.001, 'classifier__penalty': None, 'classifier__max_iter': 5000, 'classifier__fit_intercept': True, 'classifier__alpha': 0.01}\n",
      "Best cross-validation score: 0.917\n",
      "Test set score: 0.867\n",
      "\n",
      "Running Perceptron with CV = 5\n",
      "=== Results with CV = 5 ===\n",
      "Best parameters: {'pca__n_components': 3, 'classifier__tol': 0.001, 'classifier__penalty': None, 'classifier__max_iter': 5000, 'classifier__fit_intercept': True, 'classifier__alpha': 0.01}\n",
      "Best cross-validation score: 0.925\n",
      "Test set score: 0.867\n",
      "\n",
      "Running Perceptron with CV = 7\n",
      "=== Results with CV = 7 ===\n",
      "Best parameters: {'pca__n_components': None, 'classifier__tol': 0.0001, 'classifier__penalty': None, 'classifier__max_iter': 5000, 'classifier__fit_intercept': True, 'classifier__alpha': 0.01}\n",
      "Best cross-validation score: 0.900\n",
      "Test set score: 0.900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', Perceptron())\n",
    "])\n",
    "\n",
    "# Define hyperparameter space for Perceptron\n",
    "param_distributions = {\n",
    "    'pca__n_components': [None, 2, 3],\n",
    "    'classifier__penalty': ['l2', None],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "    'classifier__max_iter': [1000, 2000, 5000],\n",
    "    'classifier__tol': [1e-3, 1e-4],\n",
    "    'classifier__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Try with different CV folds\n",
    "for cv in [3, 5, 7]:\n",
    "    print(f\"\\nRunning Perceptron with CV = {cv}\")\n",
    "    search = RandomizedSearchCV(pipe, param_distributions, n_iter=20, cv=cv, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"=== Results with CV = {cv} ===\")\n",
    "    print(\"Best parameters:\", search.best_params_)\n",
    "    print(f\"Best cross-validation score: {search.best_score_:.3f}\")\n",
    "    print(f\"Test set score: {search.score(X_test, y_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running KNN with CV = 3\n",
      "=== Results with CV = 3 ===\n",
      "Best parameters: {'classifier__metric': 'manhattan', 'classifier__n_neighbors': 3, 'classifier__weights': 'uniform', 'pca__n_components': 3}\n",
      "Best cross-validation score: 0.975\n",
      "Test set score: 0.933\n",
      "\n",
      "Running KNN with CV = 5\n",
      "=== Results with CV = 5 ===\n",
      "Best parameters: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 12, 'classifier__weights': 'uniform', 'pca__n_components': None}\n",
      "Best cross-validation score: 0.967\n",
      "Test set score: 0.967\n",
      "\n",
      "Running KNN with CV = 7\n",
      "=== Results with CV = 7 ===\n",
      "Best parameters: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 7, 'classifier__weights': 'distance', 'pca__n_components': 3}\n",
      "Best cross-validation score: 0.959\n",
      "Test set score: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define hyperparameter space for KNN\n",
    "param_distributions = {\n",
    "    'pca__n_components': [None, 2, 3],\n",
    "    'classifier__n_neighbors': randint(1, 20),\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Try with different CV folds\n",
    "for cv in [3, 5, 7]:\n",
    "    print(f\"\\nRunning KNN with CV = {cv}\")\n",
    "    search = RandomizedSearchCV(pipe, param_distributions, n_iter=20, cv=cv, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"=== Results with CV = {cv} ===\")\n",
    "    print(\"Best parameters:\", search.best_params_)\n",
    "    print(f\"Best cross-validation score: {search.best_score_:.3f}\")\n",
    "    print(f\"Test set score: {search.score(X_test, y_test):.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
